{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOsy9sCd84RxDwts5ozMVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwarang97/Pytorch_introduction/blob/main/%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%99%95%EC%9D%B8_%EB%B0%8F_%EC%82%AC%EC%9A%A9%EC%9E%90%EC%A0%95%EC%9D%98_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru5SQFC-0__q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torchvision.datasets.FashionMNIST( # (60000, 28, 28)\n",
        "    root='./data/',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root='./data/',\n",
        "    train=False,\n",
        "    transform=ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=128)\n",
        "test_dataloader = DataLoader(test_data, batch_size=128)"
      ],
      "metadata": {
        "id": "rfJSfxsb1Bfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋이 제대로 들어갔는지 시각화해서 확인\n",
        "\n",
        "labels_map = {\n",
        "    0: 'T-Shirt',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle Boot',\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8,8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, rows*cols+1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item() # Tensor에서 값이 하나만 있는 걸 꺼낼때 사용\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis('off') # 축 눈금등을 없애주는 메소드, 기본값:True\n",
        "  plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g30J5aZX1DrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일에서 사용자 정의 데이터셋 만들기"
      ],
      "metadata": {
        "id": "OsjXnrhD1FSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image # ???\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "3Fsen6101IHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자정의 Dataset 클래스는 반드시 3개 함수를 구현해야 함\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path) # 지정된 경로의 이미지를 불러와 텐서로 바꿈\n",
        "    label = self.img_labesl.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_tranform(image):\n",
        "      label = self.target_transform(label)\n",
        "    sample = {'image' : image, 'label' : label}\n",
        "    return sample"
      ],
      "metadata": {
        "id": "Oi1tr2Wx1Jgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 객체는 iterable한 객체\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) # suffle : 에포치마다 섞기\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) # Tensor 이미지가 batch_size만큼 묶임"
      ],
      "metadata": {
        "id": "nHvOtUwo1Kue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지와 정답을 표시합니다\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f'Feature batch shape: {train_features.size()}')\n",
        "print(f'Lables batch shape: {train_labels.size()}')\n",
        "img = train_features[0].squeeze() # 텐서에 속해있는 1 값을 빼주는 역할 예) train_features[0] : [1, 28, 28]\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "print(f'Label: {label}')"
      ],
      "metadata": {
        "id": "ylnVkjdu1Lkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}